# Predictive_Divergency_In_ML_Algorithms_For_Mortality_Prediction

Objectives: To investigate the effects of algorithmic multiplicity in predicting covid-19 mortality by analysing error patterns and assessing the influence of patient characteristics on model decisions.
Setting: Data from the IACOV-BR database, collected from five tertiary care hospitals across all regions of Brazil.
Participants: A cohort of 4,337 patients was followed between March and August 2020. The study included adult patients (aged >18 years) with confirmed covid-19 by RT-PCR. The mean age of participants was 56.1 years (SD = 17.2), and 55.1% were male. 15.5% of participants reported ethnic identity, with 11.5% identifying as White and 3.9% as Black, Mixed, or Asian.
Outcome measures: The predictive outcome was in-hospital mortality. Model performance was assessed through the area under the ROC curve (AUC-ROC). Accuracy, precision, recall and F1-score were also computed.
Results: The models demonstrated high predictive performance on the aggregate data training (AUC ≥ 0.85) with minimal variance overall (σ2 = 0.0072) yet exhibited heterogeneous outcome prediction correlations, as reflected in R² statistics ranging from 0.56 to 0.80. Feature importance analysis, quantified via Shapley values, identified age, respiratory rate, and leukocyte count as the most consistently influential predictors. Unsupervised clustering by k-means delineated five distinct clinical profiles, with mortality rates ranging from 22% to 80%. Algorithmic performance varied significantly across these subgroups (F = 73.182316, p < 0.001). In two of the clusters, performance divergence was particularly notable: TabPFN and LightGBM outperformed others in the “Anaemia” cluster (95% CI), while TabPFN underperformed (95% CI), in the “Immunodeficient” cluster.
Conclusion: This study demonstrates that machine learning models with equivalent performance can yield divergent predictions at individual and subgroup levels, according to specific patient characteristics. All models achieved high overall discrimination with minimal variance but exhibited heterogeneous prediction correlations. Architectural similarity did not mitigate divergence. Structurally related models, such as LightGBM and Random Forest, behaved distinctly, with LightGBM aligning more closely with TabPFN. Model performance varied substantially across clinical subgroups, indicating that no single model is universally optimal. These findings indicate the need for context-aware model selection and support adaptive modelling strategies to improve predictive accuracy and equity in clinical decision-making across diverse populations.
